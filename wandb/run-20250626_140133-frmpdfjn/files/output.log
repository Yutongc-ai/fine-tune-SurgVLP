/home/yongxuan/anaconda3/envs/clip/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/yongxuan/SurgVLP/datasets/utils.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(f"{cfg.cache_dir}/{split}local_f_part{part_idx}.pt")
loading num parts:  0
loading num parts:  1
/home/yongxuan/SurgVLP/datasets/utils.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels = torch.load(f"{cfg.cache_dir}/{split}local_l_part{part_idx}.pt")
loading num parts:  2
loading num parts:  3
loading num parts:  4
num_shots is  1
num_shots is  1
Epoch 1 Loss: 0.8107 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 1 best val f1 0.4194 test f1 0.30722737312316895
Epoch 2 Loss: 0.8056 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 3 Loss: 0.8007 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 4 Loss: 0.7958 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 5 Loss: 0.7910 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 6 Loss: 0.7863 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 7 Loss: 0.7817 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 8 Loss: 0.7771 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 9 Loss: 0.7726 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 10 Loss: 0.7683 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 11 Loss: 0.7640 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 12 Loss: 0.7598 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 13 Loss: 0.7557 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 14 Loss: 0.7518 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 15 Loss: 0.7479 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 16 Loss: 0.7441 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 17 Loss: 0.7404 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 18 Loss: 0.7368 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 19 Loss: 0.7333 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 20 Loss: 0.7299 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 21 Loss: 0.7266 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 22 Loss: 0.7234 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 23 Loss: 0.7203 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 24 Loss: 0.7173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 25 Loss: 0.7144 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 26 Loss: 0.7115 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 27 Loss: 0.7088 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 28 Loss: 0.7061 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 29 Loss: 0.7035 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 30 Loss: 0.7009 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 31 Loss: 0.6985 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 32 Loss: 0.6961 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 33 Loss: 0.6938 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 34 Loss: 0.6916 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 35 Loss: 0.6894 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 36 Loss: 0.6873 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 37 Loss: 0.6853 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 38 Loss: 0.6833 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 39 Loss: 0.6814 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 40 Loss: 0.6795 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 41 Loss: 0.6778 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 41 best val f1 0.4286 test f1 0.3549360930919647
Epoch 42 Loss: 0.6760 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 43 Loss: 0.6744 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 44 Loss: 0.6727 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 45 Loss: 0.6712 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 46 Loss: 0.6696 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 46 best val f1 0.4364 test f1 0.36739251017570496
Epoch 47 Loss: 0.6682 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 48 Loss: 0.6667 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 49 Loss: 0.6654 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 50 Loss: 0.6640 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 51 Loss: 0.6627 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 52 Loss: 0.6615 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 53 Loss: 0.6603 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 54 Loss: 0.6591 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 55 Loss: 0.6579 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 56 Loss: 0.6568 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 57 Loss: 0.6558 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 58 Loss: 0.6547 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 59 Loss: 0.6537 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 60 Loss: 0.6528 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 61 Loss: 0.6518 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 62 Loss: 0.6509 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 63 Loss: 0.6500 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 63 best val f1 0.4444 test f1 0.3272380232810974
Epoch 64 Loss: 0.6492 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 65 Loss: 0.6483 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 66 Loss: 0.6475 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 67 Loss: 0.6468 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 68 Loss: 0.6460 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 69 Loss: 0.6453 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 70 Loss: 0.6445 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 71 Loss: 0.6438 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 72 Loss: 0.6432 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 73 Loss: 0.6425 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 74 Loss: 0.6419 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 75 Loss: 0.6412 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 76 Loss: 0.6406 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 77 Loss: 0.6401 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 78 Loss: 0.6395 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 79 Loss: 0.6389 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 80 Loss: 0.6384 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 81 Loss: 0.6378 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 82 Loss: 0.6373 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 83 Loss: 0.6368 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 84 Loss: 0.6363 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 85 Loss: 0.6359 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 86 Loss: 0.6354 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 87 Loss: 0.6350 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 88 Loss: 0.6345 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 89 Loss: 0.6341 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 90 Loss: 0.6337 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 91 Loss: 0.6333 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 92 Loss: 0.6329 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 93 Loss: 0.6325 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 94 Loss: 0.6321 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 95 Loss: 0.6317 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 96 Loss: 0.6314 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 97 Loss: 0.6310 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 98 Loss: 0.6307 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 99 Loss: 0.6304 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 100 Loss: 0.6300 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 101 Loss: 0.6297 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 102 Loss: 0.6294 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 103 Loss: 0.6291 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 104 Loss: 0.6288 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 105 Loss: 0.6285 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 106 Loss: 0.6282 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 107 Loss: 0.6280 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 108 Loss: 0.6277 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 109 Loss: 0.6274 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 110 Loss: 0.6272 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 111 Loss: 0.6269 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 112 Loss: 0.6267 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 113 Loss: 0.6264 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 114 Loss: 0.6262 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 115 Loss: 0.6260 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 116 Loss: 0.6258 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 117 Loss: 0.6255 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 118 Loss: 0.6253 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 119 Loss: 0.6251 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 120 Loss: 0.6249 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 121 Loss: 0.6247 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 122 Loss: 0.6245 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 123 Loss: 0.6243 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 124 Loss: 0.6241 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 125 Loss: 0.6239 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 126 Loss: 0.6238 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 127 Loss: 0.6236 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 128 Loss: 0.6234 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 129 Loss: 0.6233 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 130 Loss: 0.6231 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 131 Loss: 0.6229 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 132 Loss: 0.6228 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 133 Loss: 0.6226 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 134 Loss: 0.6225 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 135 Loss: 0.6223 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 136 Loss: 0.6222 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 137 Loss: 0.6220 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 138 Loss: 0.6219 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 139 Loss: 0.6217 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 140 Loss: 0.6216 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 141 Loss: 0.6215 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 142 Loss: 0.6214 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 143 Loss: 0.6212 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 144 Loss: 0.6211 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 145 Loss: 0.6210 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 146 Loss: 0.6209 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 147 Loss: 0.6208 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 148 Loss: 0.6206 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 149 Loss: 0.6205 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 150 Loss: 0.6204 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 151 Loss: 0.6203 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 152 Loss: 0.6202 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 153 Loss: 0.6201 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 154 Loss: 0.6200 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 155 Loss: 0.6199 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 156 Loss: 0.6198 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 157 Loss: 0.6197 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 158 Loss: 0.6196 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 159 Loss: 0.6195 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 160 Loss: 0.6194 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 161 Loss: 0.6194 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 162 Loss: 0.6193 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 163 Loss: 0.6192 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 164 Loss: 0.6191 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 165 Loss: 0.6190 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 166 Loss: 0.6189 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 167 Loss: 0.6189 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 168 Loss: 0.6188 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 169 Loss: 0.6187 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 170 Loss: 0.6186 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 171 Loss: 0.6186 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 172 Loss: 0.6185 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 173 Loss: 0.6184 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 174 Loss: 0.6184 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 175 Loss: 0.6183 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 176 Loss: 0.6182 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 177 Loss: 0.6182 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 178 Loss: 0.6181 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 179 Loss: 0.6180 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 180 Loss: 0.6180 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 181 Loss: 0.6179 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 182 Loss: 0.6179 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 183 Loss: 0.6178 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 184 Loss: 0.6178 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 185 Loss: 0.6177 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 186 Loss: 0.6177 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 187 Loss: 0.6176 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 188 Loss: 0.6175 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 189 Loss: 0.6175 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 190 Loss: 0.6174 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 191 Loss: 0.6174 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 192 Loss: 0.6173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 193 Loss: 0.6173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 194 Loss: 0.6173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 195 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 196 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 197 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 198 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 199 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 200 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 201 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 202 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 203 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 204 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 205 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 206 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 207 Loss: 0.6167 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 208 Loss: 0.6167 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 209 Loss: 0.6167 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 210 Loss: 0.6166 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 211 Loss: 0.6166 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 212 Loss: 0.6166 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 213 Loss: 0.6165 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 214 Loss: 0.6165 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 215 Loss: 0.6165 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 216 Loss: 0.6164 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 217 Loss: 0.6164 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 218 Loss: 0.6164 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 219 Loss: 0.6163 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 220 Loss: 0.6163 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 221 Loss: 0.6163 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 222 Loss: 0.6163 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 223 Loss: 0.6162 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 224 Loss: 0.6162 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 225 Loss: 0.6162 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 226 Loss: 0.6162 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 227 Loss: 0.6161 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 228 Loss: 0.6161 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 229 Loss: 0.6161 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 230 Loss: 0.6161 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 231 Loss: 0.6160 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 232 Loss: 0.6160 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 233 Loss: 0.6160 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 234 Loss: 0.6160 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 235 Loss: 0.6160 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 236 Loss: 0.6159 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 237 Loss: 0.6159 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 238 Loss: 0.6159 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 239 Loss: 0.6159 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 240 Loss: 0.6159 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 241 Loss: 0.6158 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 242 Loss: 0.6158 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 243 Loss: 0.6158 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 244 Loss: 0.6158 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 245 Loss: 0.6158 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 246 Loss: 0.6157 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 247 Loss: 0.6157 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 248 Loss: 0.6157 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 249 Loss: 0.6157 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 250 Loss: 0.6157 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 251 Loss: 0.6157 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 252 Loss: 0.6156 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 253 Loss: 0.6156 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 254 Loss: 0.6156 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 255 Loss: 0.6156 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 256 Loss: 0.6156 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 257 Loss: 0.6156 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 258 Loss: 0.6156 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 259 Loss: 0.6156 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 260 Loss: 0.6155 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 261 Loss: 0.6155 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 262 Loss: 0.6155 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 263 Loss: 0.6155 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 264 Loss: 0.6155 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 265 Loss: 0.6155 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 266 Loss: 0.6155 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 267 Loss: 0.6155 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 268 Loss: 0.6154 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 269 Loss: 0.6154 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 270 Loss: 0.6154 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 271 Loss: 0.6154 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 272 Loss: 0.6154 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 273 Loss: 0.6154 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 274 Loss: 0.6154 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 275 Loss: 0.6154 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 276 Loss: 0.6154 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 277 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 278 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 279 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 280 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 281 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 282 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 283 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 284 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 285 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 286 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 287 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 288 Loss: 0.6153 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 289 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 290 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 291 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 292 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 293 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 294 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 295 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 296 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 297 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 298 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 299 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 300 Loss: 0.6152 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)