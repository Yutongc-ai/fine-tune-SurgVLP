/home/yongxuan/anaconda3/envs/clip/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
loading num parts:  0
loading num parts:  1
loading num parts:  2
/home/yongxuan/SurgVLP/datasets/utils.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(f"{cfg.cache_dir}/{split}local_f_part{part_idx}.pt")
/home/yongxuan/SurgVLP/datasets/utils.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels = torch.load(f"{cfg.cache_dir}/{split}local_l_part{part_idx}.pt")
loading num parts:  3
loading num parts:  4
num_shots is  16
num_shots is  16
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 1 Loss: 1.6171
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.83it/s]
  0%|                                                                          | 0/2 [00:00<?, ?it/s]
Epoch 1 best val f1 0.3721 test f1 0.417346715927124
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])

100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.21it/s]
Epoch 2 best val f1 0.5209 test f1 0.5264657735824585
 50%|█████████████████████████████████                                 | 1/2 [00:00<00:00,  1.95it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])

100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.20it/s]
Epoch 3 best val f1 0.5512 test f1 0.48106706142425537
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 4 Loss: -0.2239
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.27it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 5 Loss: -0.2917
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.27it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 6 Loss: -0.2983
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.26it/s]
  0%|                                                                          | 0/2 [00:00<?, ?it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.16it/s]
  0%|                                                                          | 0/2 [00:00<?, ?it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])

100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.24it/s]
Epoch 8 best val f1 0.5546 test f1 0.4234750270843506
torch.Size([64, 49, 768])
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.18it/s]
torch.Size([48, 49, 768])
Epoch 9 Loss: -0.3961
Epoch 9 best val f1 0.5625 test f1 0.422041118144989
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 10 Loss: -0.4209
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 11 Loss: -0.4499
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.23it/s]
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.25it/s]
Epoch 11 best val f1 0.5866 test f1 0.42229750752449036
torch.Size([64, 49, 768])
 50%|█████████████████████████████████                                 | 1/2 [00:00<00:00,  1.99it/s]
torch.Size([48, 49, 768])
Epoch 12 Loss: -0.4806
torch.Size([64, 49, 768])
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.26it/s]
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.27it/s]
Epoch 13 Loss: -0.5073
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 14 Loss: -0.5404
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.26it/s]
  0%|                                                                          | 0/2 [00:00<?, ?it/s]
Epoch 14 best val f1 0.5879 test f1 0.4321037232875824
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])

100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.26it/s]
Epoch 15 best val f1 0.5914 test f1 0.438062459230423
  0%|                                                                          | 0/2 [00:00<?, ?it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.92it/s]
  0%|                                                                          | 0/2 [00:00<?, ?it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 17 Loss: -0.6314
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.11it/s]
 50%|█████████████████████████████████                                 | 1/2 [00:00<00:00,  1.96it/s]
torch.Size([48, 49, 768])
Epoch 18 Loss: -0.6595
torch.Size([64, 49, 768])
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.26it/s]
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.24it/s]
Epoch 19 Loss: -0.6856
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 20 Loss: -0.7072
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.23it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 21 Loss: -0.7353
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.23it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 22 Loss: -0.7540
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.15it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 23 Loss: -0.7751
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.20it/s]
  0%|                                                                          | 0/2 [00:00<?, ?it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.24it/s]
  0%|                                                                          | 0/2 [00:00<?, ?it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.25it/s]
 50%|█████████████████████████████████                                 | 1/2 [00:00<00:00,  1.95it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 26 Loss: -0.8156
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.26it/s]
 50%|█████████████████████████████████                                 | 1/2 [00:00<00:00,  1.97it/s]
torch.Size([48, 49, 768])
Epoch 27 Loss: -0.8342
torch.Size([64, 49, 768])
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.26it/s]
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.24it/s]
Epoch 28 Loss: -0.8480
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 29 Loss: -0.8584
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.25it/s]
torch.Size([64, 49, 768])
torch.Size([48, 49, 768])
Epoch 30 Loss: -0.8675
100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.26it/s]