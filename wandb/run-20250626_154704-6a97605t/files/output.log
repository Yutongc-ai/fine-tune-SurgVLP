/home/yongxuan/anaconda3/envs/clip/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/yongxuan/SurgVLP/datasets/utils.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(f"{cfg.cache_dir}/{split}local_f_part{part_idx}.pt")
loading num parts:  0
loading num parts:  1
/home/yongxuan/SurgVLP/datasets/utils.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels = torch.load(f"{cfg.cache_dir}/{split}local_l_part{part_idx}.pt")
loading num parts:  2
loading num parts:  3
loading num parts:  4
num_shots is  4
num_shots is  4
Epoch 1 Loss: 1.0028 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 1 best val f1 0.4382 test f1 0.3057743310928345
Epoch 2 Loss: 0.9932 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 3 Loss: 0.9838 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 4 Loss: 0.9745 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 5 Loss: 0.9653 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 6 Loss: 0.9562 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 7 Loss: 0.9472 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 8 Loss: 0.9384 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 9 Loss: 0.9297 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 10 Loss: 0.9212 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 11 Loss: 0.9128 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 12 Loss: 0.9045 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 13 Loss: 0.8964 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 14 Loss: 0.8884 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 15 Loss: 0.8806 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 16 Loss: 0.8730 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 17 Loss: 0.8655 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 18 Loss: 0.8582 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 19 Loss: 0.8510 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 20 Loss: 0.8440 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 21 Loss: 0.8372 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 22 Loss: 0.8305 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 23 Loss: 0.8240 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 24 Loss: 0.8177 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 25 Loss: 0.8115 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 26 Loss: 0.8054 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 27 Loss: 0.7995 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 28 Loss: 0.7938 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 29 Loss: 0.7882 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 30 Loss: 0.7828 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 31 Loss: 0.7776 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 32 Loss: 0.7724 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 33 Loss: 0.7675 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 34 Loss: 0.7626 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 35 Loss: 0.7579 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 36 Loss: 0.7534 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 37 Loss: 0.7490 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 38 Loss: 0.7447 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 39 Loss: 0.7405 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 40 Loss: 0.7365 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 41 Loss: 0.7326 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 42 Loss: 0.7288 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 43 Loss: 0.7251 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 44 Loss: 0.7216 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 45 Loss: 0.7181 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 46 Loss: 0.7148 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 47 Loss: 0.7115 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 48 Loss: 0.7084 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 49 Loss: 0.7054 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 50 Loss: 0.7024 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 51 Loss: 0.6996 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 52 Loss: 0.6968 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 52 best val f1 0.4400 test f1 0.3107721507549286
Epoch 53 Loss: 0.6941 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 53 best val f1 0.4596 test f1 0.32672175765037537
Epoch 54 Loss: 0.6916 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 54 best val f1 0.4976 test f1 0.36497634649276733
Epoch 55 Loss: 0.6891 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 55 best val f1 0.5281 test f1 0.42732101678848267
Epoch 56 Loss: 0.6866 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 56 best val f1 0.5658 test f1 0.5073747634887695
Epoch 57 Loss: 0.6843 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 57 best val f1 0.5891 test f1 0.587769627571106
Epoch 58 Loss: 0.6820 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 58 best val f1 0.5946 test f1 0.643407940864563
Epoch 59 Loss: 0.6798 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 60 Loss: 0.6777 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 61 Loss: 0.6757 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 62 Loss: 0.6737 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 63 Loss: 0.6717 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 64 Loss: 0.6699 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 65 Loss: 0.6681 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 66 Loss: 0.6663 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 67 Loss: 0.6647 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 68 Loss: 0.6630 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 69 Loss: 0.6614 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 70 Loss: 0.6599 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 71 Loss: 0.6584 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 72 Loss: 0.6570 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 73 Loss: 0.6556 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 74 Loss: 0.6543 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 75 Loss: 0.6530 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 76 Loss: 0.6518 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 77 Loss: 0.6506 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 78 Loss: 0.6494 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 79 Loss: 0.6483 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 80 Loss: 0.6472 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 81 Loss: 0.6461 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 82 Loss: 0.6451 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 83 Loss: 0.6441 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 84 Loss: 0.6432 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 85 Loss: 0.6422 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 86 Loss: 0.6413 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 87 Loss: 0.6405 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 88 Loss: 0.6396 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 89 Loss: 0.6388 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 90 Loss: 0.6380 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 91 Loss: 0.6373 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 92 Loss: 0.6366 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 93 Loss: 0.6359 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 94 Loss: 0.6352 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 95 Loss: 0.6345 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 96 Loss: 0.6339 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 97 Loss: 0.6333 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 98 Loss: 0.6327 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 99 Loss: 0.6321 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 100 Loss: 0.6315 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 101 Loss: 0.6310 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 102 Loss: 0.6305 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 103 Loss: 0.6300 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 104 Loss: 0.6295 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 105 Loss: 0.6290 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 106 Loss: 0.6286 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 107 Loss: 0.6281 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 108 Loss: 0.6277 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 109 Loss: 0.6273 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 110 Loss: 0.6269 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 111 Loss: 0.6265 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 112 Loss: 0.6261 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 113 Loss: 0.6258 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 114 Loss: 0.6254 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 115 Loss: 0.6251 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 116 Loss: 0.6247 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 117 Loss: 0.6244 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 118 Loss: 0.6241 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 119 Loss: 0.6238 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 120 Loss: 0.6235 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 121 Loss: 0.6233 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 122 Loss: 0.6230 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 123 Loss: 0.6227 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 124 Loss: 0.6225 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 125 Loss: 0.6222 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 126 Loss: 0.6220 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 127 Loss: 0.6218 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 128 Loss: 0.6216 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 129 Loss: 0.6213 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 130 Loss: 0.6211 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 131 Loss: 0.6209 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 132 Loss: 0.6207 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 133 Loss: 0.6206 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 134 Loss: 0.6204 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 135 Loss: 0.6202 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 136 Loss: 0.6200 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 137 Loss: 0.6199 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 138 Loss: 0.6197 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 139 Loss: 0.6195 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 140 Loss: 0.6194 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 141 Loss: 0.6193 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 142 Loss: 0.6191 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 143 Loss: 0.6190 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 144 Loss: 0.6188 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 145 Loss: 0.6187 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 146 Loss: 0.6186 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 147 Loss: 0.6185 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 148 Loss: 0.6184 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 149 Loss: 0.6182 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 150 Loss: 0.6181 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 151 Loss: 0.6180 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 152 Loss: 0.6179 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 153 Loss: 0.6178 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 154 Loss: 0.6177 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 155 Loss: 0.6176 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 156 Loss: 0.6176 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 157 Loss: 0.6175 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 158 Loss: 0.6174 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 159 Loss: 0.6173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 160 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 161 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 162 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 163 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 164 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 165 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 166 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 167 Loss: 0.6167 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 168 Loss: 0.6167 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 169 Loss: 0.6166 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 170 Loss: 0.6166 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 171 Loss: 0.6165 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 172 Loss: 0.6164 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 173 Loss: 0.6164 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 174 Loss: 0.6163 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 175 Loss: 0.6163 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 176 Loss: 0.6162 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 177 Loss: 0.6162 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 178 Loss: 0.6162 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 179 Loss: 0.6161 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 180 Loss: 0.6161 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 181 Loss: 0.6160 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 182 Loss: 0.6160 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 183 Loss: 0.6160 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 184 Loss: 0.6159 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 185 Loss: 0.6159 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Traceback (most recent call last):
  File "few_shot.py", line 82, in <module>
    main(configs[args.method], args.method)
  File "few_shot.py", line 58, in main
    metrics = method(dataset)
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yongxuan/SurgVLP/methods/linear_probe_plus.py", line 261, in forward
    for i, (images, target) in enumerate(train_loader):
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yongxuan/SurgVLP/datasets/utils.py", line 303, in __getitem__
    img0 = read_image(item.impath)
  File "/home/yongxuan/SurgVLP/datasets/utils.py", line 146, in read_image
    img = Image.open(path).convert('RGB')
  File "/home/yongxuan/.local/lib/python3.8/site-packages/PIL/Image.py", line 921, in convert
    self.load()
  File "/home/yongxuan/.local/lib/python3.8/site-packages/PIL/ImageFile.py", line 260, in load
    n, err_code = decoder.decode(b)
KeyboardInterrupt