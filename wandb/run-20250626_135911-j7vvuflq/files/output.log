/home/yongxuan/anaconda3/envs/clip/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/yongxuan/SurgVLP/datasets/utils.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(f"{cfg.cache_dir}/{split}local_f_part{part_idx}.pt")
loading num parts:  0
loading num parts:  1
/home/yongxuan/SurgVLP/datasets/utils.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels = torch.load(f"{cfg.cache_dir}/{split}local_l_part{part_idx}.pt")
loading num parts:  2
loading num parts:  3
loading num parts:  4
num_shots is  1
num_shots is  1
Epoch 1 Loss: 0.8789 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 1 best val f1 0.4194 test f1 0.3060985803604126
Epoch 2 Loss: 0.8723 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 3 Loss: 0.8658 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 4 Loss: 0.8594 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 5 Loss: 0.8530 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 6 Loss: 0.8468 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 7 Loss: 0.8406 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 8 Loss: 0.8346 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 9 Loss: 0.8286 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 10 Loss: 0.8228 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 11 Loss: 0.8171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 12 Loss: 0.8115 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 13 Loss: 0.8060 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 14 Loss: 0.8006 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 15 Loss: 0.7954 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 16 Loss: 0.7902 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 17 Loss: 0.7852 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 18 Loss: 0.7804 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 19 Loss: 0.7756 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 20 Loss: 0.7710 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 21 Loss: 0.7665 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 22 Loss: 0.7621 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 23 Loss: 0.7578 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 24 Loss: 0.7537 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 25 Loss: 0.7497 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 26 Loss: 0.7458 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 27 Loss: 0.7420 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 28 Loss: 0.7383 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 29 Loss: 0.7347 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 30 Loss: 0.7313 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 31 Loss: 0.7279 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 32 Loss: 0.7247 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 33 Loss: 0.7215 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 34 Loss: 0.7185 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 35 Loss: 0.7155 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 36 Loss: 0.7127 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 37 Loss: 0.7099 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 38 Loss: 0.7072 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 38 best val f1 0.4262 test f1 0.29629936814308167
Epoch 39 Loss: 0.7046 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 40 Loss: 0.7021 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 41 Loss: 0.6997 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 42 Loss: 0.6973 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 42 best val f1 0.4333 test f1 0.28649628162384033
Epoch 43 Loss: 0.6950 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 44 Loss: 0.6928 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 45 Loss: 0.6907 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 45 best val f1 0.4407 test f1 0.27717873454093933
Epoch 46 Loss: 0.6886 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 47 Loss: 0.6866 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 48 Loss: 0.6846 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 49 Loss: 0.6827 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 49 best val f1 0.4483 test f1 0.26706889271736145
Epoch 50 Loss: 0.6809 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 51 Loss: 0.6791 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 52 Loss: 0.6774 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 53 Loss: 0.6758 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 53 best val f1 0.4615 test f1 0.2627430856227875
Epoch 54 Loss: 0.6742 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 55 Loss: 0.6726 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 55 best val f1 0.4800 test f1 0.26343604922294617
Epoch 56 Loss: 0.6711 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 57 Loss: 0.6696 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 58 Loss: 0.6682 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 59 Loss: 0.6668 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 59 best val f1 0.5000 test f1 0.27253568172454834
Epoch 60 Loss: 0.6655 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 60 best val f1 0.5263 test f1 0.27637797594070435
Epoch 61 Loss: 0.6642 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 62 Loss: 0.6630 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 63 Loss: 0.6618 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 64 Loss: 0.6606 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 65 Loss: 0.6595 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 66 Loss: 0.6584 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 67 Loss: 0.6573 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 68 Loss: 0.6562 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 68 best val f1 0.5714 test f1 0.3184775412082672
Epoch 69 Loss: 0.6552 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 69 best val f1 0.5926 test f1 0.3244485557079315
Epoch 70 Loss: 0.6543 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 71 Loss: 0.6533 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 71 best val f1 0.6154 test f1 0.33597812056541443
Epoch 72 Loss: 0.6524 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 73 Loss: 0.6515 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 74 Loss: 0.6506 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 75 Loss: 0.6498 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 76 Loss: 0.6490 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 77 Loss: 0.6482 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 78 Loss: 0.6474 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 79 Loss: 0.6466 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 80 Loss: 0.6459 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 81 Loss: 0.6452 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 82 Loss: 0.6445 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 83 Loss: 0.6438 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 84 Loss: 0.6432 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 85 Loss: 0.6426 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 86 Loss: 0.6420 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 87 Loss: 0.6414 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 88 Loss: 0.6408 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 89 Loss: 0.6402 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 90 Loss: 0.6397 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 91 Loss: 0.6391 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 92 Loss: 0.6386 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 93 Loss: 0.6381 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 94 Loss: 0.6376 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 95 Loss: 0.6371 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 96 Loss: 0.6367 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 97 Loss: 0.6362 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 98 Loss: 0.6358 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 99 Loss: 0.6353 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 100 Loss: 0.6349 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 101 Loss: 0.6345 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 102 Loss: 0.6341 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 103 Loss: 0.6337 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 104 Loss: 0.6333 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 105 Loss: 0.6330 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 106 Loss: 0.6326 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 107 Loss: 0.6322 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 108 Loss: 0.6319 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 109 Loss: 0.6316 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 110 Loss: 0.6312 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 111 Loss: 0.6309 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 112 Loss: 0.6306 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 113 Loss: 0.6303 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 114 Loss: 0.6300 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 115 Loss: 0.6297 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 116 Loss: 0.6294 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 117 Loss: 0.6292 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 118 Loss: 0.6289 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 119 Loss: 0.6286 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 120 Loss: 0.6284 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 121 Loss: 0.6281 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 122 Loss: 0.6279 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 123 Loss: 0.6276 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 124 Loss: 0.6274 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 125 Loss: 0.6272 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 126 Loss: 0.6269 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 127 Loss: 0.6267 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 128 Loss: 0.6265 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 129 Loss: 0.6263 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 130 Loss: 0.6261 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 131 Loss: 0.6259 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 132 Loss: 0.6257 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 133 Loss: 0.6255 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 134 Loss: 0.6253 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 135 Loss: 0.6252 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 136 Loss: 0.6250 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 137 Loss: 0.6248 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 138 Loss: 0.6246 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 139 Loss: 0.6245 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 140 Loss: 0.6243 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 141 Loss: 0.6241 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 142 Loss: 0.6240 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 143 Loss: 0.6238 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 144 Loss: 0.6237 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 145 Loss: 0.6235 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 146 Loss: 0.6234 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 147 Loss: 0.6233 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 148 Loss: 0.6231 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 149 Loss: 0.6230 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 150 Loss: 0.6229 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 151 Loss: 0.6227 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 152 Loss: 0.6226 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 153 Loss: 0.6225 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 154 Loss: 0.6224 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 155 Loss: 0.6222 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 156 Loss: 0.6221 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 157 Loss: 0.6220 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 158 Loss: 0.6219 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 159 Loss: 0.6218 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 160 Loss: 0.6217 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 161 Loss: 0.6216 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 162 Loss: 0.6215 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 163 Loss: 0.6214 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 164 Loss: 0.6213 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 165 Loss: 0.6212 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 166 Loss: 0.6211 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 167 Loss: 0.6210 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 168 Loss: 0.6209 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 169 Loss: 0.6208 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 170 Loss: 0.6208 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 171 Loss: 0.6207 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 172 Loss: 0.6206 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 173 Loss: 0.6205 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 174 Loss: 0.6204 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 175 Loss: 0.6203 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 176 Loss: 0.6203 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 177 Loss: 0.6202 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 178 Loss: 0.6201 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 179 Loss: 0.6201 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 180 Loss: 0.6200 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 181 Loss: 0.6199 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 182 Loss: 0.6198 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 183 Loss: 0.6198 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 184 Loss: 0.6197 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 185 Loss: 0.6197 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 186 Loss: 0.6196 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 187 Loss: 0.6195 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 188 Loss: 0.6195 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 189 Loss: 0.6194 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 190 Loss: 0.6194 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 191 Loss: 0.6193 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 192 Loss: 0.6192 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 193 Loss: 0.6192 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 194 Loss: 0.6191 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 195 Loss: 0.6191 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 196 Loss: 0.6190 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 197 Loss: 0.6190 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 198 Loss: 0.6189 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 199 Loss: 0.6189 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 200 Loss: 0.6188 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 201 Loss: 0.6188 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 202 Loss: 0.6188 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 203 Loss: 0.6187 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 204 Loss: 0.6187 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 205 Loss: 0.6186 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 206 Loss: 0.6186 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 207 Loss: 0.6185 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 208 Loss: 0.6185 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 209 Loss: 0.6185 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 210 Loss: 0.6184 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 211 Loss: 0.6184 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 212 Loss: 0.6183 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 213 Loss: 0.6183 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 214 Loss: 0.6183 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 215 Loss: 0.6182 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 216 Loss: 0.6182 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 217 Loss: 0.6182 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 218 Loss: 0.6181 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 219 Loss: 0.6181 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 220 Loss: 0.6181 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 221 Loss: 0.6180 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 222 Loss: 0.6180 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 223 Loss: 0.6180 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 224 Loss: 0.6180 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 225 Loss: 0.6179 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 226 Loss: 0.6179 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 227 Loss: 0.6179 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 228 Loss: 0.6178 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 229 Loss: 0.6178 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 230 Loss: 0.6178 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 231 Loss: 0.6178 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 232 Loss: 0.6177 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 233 Loss: 0.6177 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 234 Loss: 0.6177 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 235 Loss: 0.6177 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 236 Loss: 0.6176 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 237 Loss: 0.6176 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 238 Loss: 0.6176 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 239 Loss: 0.6176 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 240 Loss: 0.6175 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 241 Loss: 0.6175 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 242 Loss: 0.6175 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 243 Loss: 0.6175 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 244 Loss: 0.6175 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 245 Loss: 0.6174 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 246 Loss: 0.6174 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 247 Loss: 0.6174 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 248 Loss: 0.6174 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 249 Loss: 0.6174 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 250 Loss: 0.6174 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 251 Loss: 0.6173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 252 Loss: 0.6173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 253 Loss: 0.6173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 254 Loss: 0.6173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 255 Loss: 0.6173 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 256 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 257 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 258 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 259 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 260 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 261 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 262 Loss: 0.6172 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 263 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 264 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 265 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 266 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 267 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 268 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 269 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 270 Loss: 0.6171 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 271 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 272 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 273 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 274 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 275 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 276 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 277 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 278 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 279 Loss: 0.6170 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 280 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 281 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 282 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 283 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 284 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 285 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 286 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 287 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 288 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 289 Loss: 0.6169 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 290 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 291 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 292 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 293 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 294 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 295 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 296 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 297 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 298 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 299 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)
Epoch 300 Loss: 0.6168 Alpha: tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>)