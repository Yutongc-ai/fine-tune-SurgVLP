/home/yongxuan/anaconda3/envs/clip/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/yongxuan/SurgVLP/datasets/utils.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(f"{cfg.cache_dir}/{split}local_f_part{part_idx}.pt")
loading num parts:  0
loading num parts:  1
/home/yongxuan/SurgVLP/datasets/utils.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels = torch.load(f"{cfg.cache_dir}/{split}local_l_part{part_idx}.pt")
loading num parts:  2
loading num parts:  3
loading num parts:  4
  0%|                                                                         | 0/28 [00:00<?, ?it/s]
Epoch 0 test f1 0.28642749786376953
num_shots is  256








100%|████████████████████████████████████████████████████████████████| 28/28 [00:15<00:00,  1.75it/s]
Epoch 1 Loss: 0.5687
  0%|                                                                         | 0/28 [00:00<?, ?it/s]







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 2 Loss: -0.3306
  4%|██▎                                                              | 1/28 [00:00<00:13,  1.96it/s]







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 3 Loss: -0.6945
Epoch 3 best val f1 0.7159 test f1 0.3590630888938904






 93%|███████████████████████████████████████████████████████████▍    | 26/28 [00:13<00:01,  1.99it/s]

100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.97it/s]
  0%|                                                                         | 0/28 [00:00<?, ?it/s]







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 5 Loss: -0.9081







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.96it/s]
Epoch 6 Loss: -0.9327







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.98it/s]
Epoch 7 Loss: -0.9441







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.97it/s]
Epoch 8 Loss: -0.9527







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 9 Loss: -0.9615







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.98it/s]
Epoch 10 Loss: -0.9662






 96%|█████████████████████████████████████████████████████████████▋  | 27/28 [00:13<00:00,  1.99it/s]

100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]






 96%|█████████████████████████████████████████████████████████████▋  | 27/28 [00:13<00:00,  2.00it/s]

100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 13 Loss: -0.9763







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.97it/s]
Epoch 14 Loss: -0.9799







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.98it/s]
Epoch 15 Loss: -0.9816







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 16 Loss: -0.9834







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.98it/s]
Epoch 17 Loss: -0.9833






 96%|█████████████████████████████████████████████████████████████▋  | 27/28 [00:13<00:00,  1.98it/s]

100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]




100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 19 Loss: -0.9855







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 20 Loss: -0.9852







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.98it/s]
Epoch 21 Loss: -0.9869





 68%|███████████████████████████████████████████▍                    | 19/28 [00:09<00:04,  1.98it/s]

100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.97it/s]
Epoch 23 Loss: -0.9871







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 24 Loss: -0.9882





 96%|█████████████████████████████████████████████████████████████▋  | 27/28 [00:13<00:00,  2.00it/s]

100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]






 96%|█████████████████████████████████████████████████████████████▋  | 27/28 [00:13<00:00,  2.00it/s]

100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.98it/s]
Epoch 27 Loss: -0.9917







100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 28 Loss: -0.9917






100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 29 Loss: -0.9929





100%|████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.99it/s]
Epoch 30 Loss: -0.9935