/home/yongxuan/anaconda3/envs/clip/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/yongxuan/SurgVLP/datasets/utils.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(f"{cfg.cache_dir}/{split}local_f_part{part_idx}.pt")
loading num parts:  0
loading num parts:  1
loading num parts:  2
/home/yongxuan/SurgVLP/datasets/utils.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels = torch.load(f"{cfg.cache_dir}/{split}local_l_part{part_idx}.pt")
loading num parts:  3
loading num parts:  4
num_shots is  64
num_shots is  64
Epoch 1 Loss: 0.9532
Epoch 1 best val f1 0.4154 test f1 0.3057743310928345
Epoch 2 Loss: 0.8528
Epoch 3 Loss: 0.7884
Epoch 3 best val f1 0.4157 test f1 0.3057743310928345
Epoch 4 Loss: 0.7442
Epoch 4 best val f1 0.4161 test f1 0.3057771325111389
Epoch 5 Loss: 0.7120
Epoch 5 best val f1 0.4208 test f1 0.30588793754577637
Epoch 6 Loss: 0.6870
Epoch 6 best val f1 0.4376 test f1 0.3064928948879242
Epoch 7 Loss: 0.6668
Epoch 7 best val f1 0.4612 test f1 0.3092721402645111
Epoch 8 Loss: 0.6490
Epoch 8 best val f1 0.4935 test f1 0.31596529483795166
Epoch 9 Loss: 0.6323
Epoch 9 best val f1 0.5153 test f1 0.3276492655277252
Epoch 10 Loss: 0.6168
Epoch 11 Loss: 0.6013
Epoch 12 Loss: 0.5853
Epoch 13 Loss: 0.5700
Epoch 14 Loss: 0.5556
Epoch 15 Loss: 0.5442
Epoch 16 Loss: 0.5369
Epoch 17 Loss: 0.5331
Epoch 18 Loss: 0.5299
Epoch 19 Loss: 0.5278
Epoch 20 Loss: 0.5264
Epoch 21 Loss: 0.5251
Epoch 22 Loss: 0.5242
Epoch 23 Loss: 0.5230
Epoch 24 Loss: 0.5226
Epoch 25 Loss: 0.5222
Epoch 26 Loss: 0.5201
Epoch 27 Loss: 0.5188
Epoch 28 Loss: 0.5196
Epoch 29 Loss: 0.5185
Epoch 30 Loss: 0.5171
Epoch 31 Loss: 0.5179
Epoch 32 Loss: 0.5165
Epoch 33 Loss: 0.5162
Epoch 34 Loss: 0.5155
Epoch 35 Loss: 0.5158
Epoch 36 Loss: 0.5148
Epoch 37 Loss: 0.5145
Epoch 38 Loss: 0.5150
Epoch 39 Loss: 0.5144
Epoch 40 Loss: 0.5140
Epoch 41 Loss: 0.5135
Epoch 42 Loss: 0.5134
Epoch 43 Loss: 0.5132
Epoch 44 Loss: 0.5132
Epoch 45 Loss: 0.5127
Epoch 46 Loss: 0.5127
Epoch 47 Loss: 0.5135
Epoch 48 Loss: 0.5129
Epoch 49 Loss: 0.5117
Epoch 50 Loss: 0.5125
Epoch 51 Loss: 0.5131
Epoch 52 Loss: 0.5121
Epoch 53 Loss: 0.5113
Epoch 54 Loss: 0.5121
Epoch 55 Loss: 0.5115
Epoch 56 Loss: 0.5113
Epoch 57 Loss: 0.5104
Epoch 58 Loss: 0.5110
Epoch 59 Loss: 0.5104
Epoch 60 Loss: 0.5105
Epoch 61 Loss: 0.5105
Epoch 62 Loss: 0.5101
Epoch 63 Loss: 0.5096
Epoch 64 Loss: 0.5096
Epoch 65 Loss: 0.5093
Epoch 66 Loss: 0.5084
Epoch 67 Loss: 0.5092
Epoch 68 Loss: 0.5092
Epoch 69 Loss: 0.5084
Epoch 70 Loss: 0.5084
Epoch 71 Loss: 0.5083
Epoch 72 Loss: 0.5082
Epoch 73 Loss: 0.5081
Epoch 74 Loss: 0.5085
Epoch 75 Loss: 0.5077
Epoch 76 Loss: 0.5081
Epoch 77 Loss: 0.5078
Epoch 78 Loss: 0.5070
Epoch 79 Loss: 0.5067
Epoch 80 Loss: 0.5066
Epoch 81 Loss: 0.5067
Epoch 82 Loss: 0.5064
Epoch 83 Loss: 0.5053
Epoch 84 Loss: 0.5048
Epoch 85 Loss: 0.5062
Epoch 86 Loss: 0.5049
Epoch 87 Loss: 0.5047
Epoch 88 Loss: 0.5083
Epoch 89 Loss: 0.5082
Epoch 90 Loss: 0.5071
Epoch 91 Loss: 0.5091
Epoch 92 Loss: 0.5085
Epoch 93 Loss: 0.5084
Epoch 94 Loss: 0.5091
Epoch 95 Loss: 0.5094
Epoch 96 Loss: 0.5082
Epoch 97 Loss: 0.5076
Epoch 98 Loss: 0.5082
Epoch 99 Loss: 0.5082
Epoch 100 Loss: 0.5079
Epoch 101 Loss: 0.5072
Epoch 102 Loss: 0.5080
Epoch 103 Loss: 0.5078
Epoch 104 Loss: 0.5071
Epoch 105 Loss: 0.5076
Epoch 106 Loss: 0.5068
Epoch 107 Loss: 0.5066
Epoch 108 Loss: 0.5076
Epoch 109 Loss: 0.5073
Epoch 110 Loss: 0.5067
Epoch 111 Loss: 0.5063
Epoch 112 Loss: 0.5073
Epoch 113 Loss: 0.5068
Epoch 114 Loss: 0.5072
Epoch 115 Loss: 0.5057
Epoch 116 Loss: 0.5054
Epoch 117 Loss: 0.5058
Epoch 118 Loss: 0.5053
Epoch 119 Loss: 0.5044
Epoch 120 Loss: 0.5039
Epoch 121 Loss: 0.5018
Epoch 122 Loss: 0.5005
Epoch 123 Loss: 0.4993
Epoch 124 Loss: 0.4962
Epoch 125 Loss: 0.4950
Epoch 126 Loss: 0.4925
Epoch 127 Loss: 0.4891
Epoch 128 Loss: 0.4862
Epoch 129 Loss: 0.4833
Epoch 130 Loss: 0.4857
Epoch 131 Loss: 0.4777
Epoch 132 Loss: 0.4725
Epoch 133 Loss: 0.4662
Epoch 134 Loss: 0.4773
Epoch 135 Loss: 0.4906
Epoch 136 Loss: 0.4818
Traceback (most recent call last):
  File "few_shot.py", line 76, in <module>
    main(configs[args.method], args.method)
  File "few_shot.py", line 52, in main
    metrics = method(dataset)
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yongxuan/SurgVLP/methods/linear_probe_plus.py", line 300, in forward
    val_metrics = self.get_val_metrics(val_loader)
  File "/home/yongxuan/SurgVLP/methods/linear_probe_plus.py", line 104, in get_val_metrics
    for val_images, val_labels in val_loader:
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yongxuan/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yongxuan/SurgVLP/datasets/utils.py", line 303, in __getitem__
    img0 = read_image(item.impath)
  File "/home/yongxuan/SurgVLP/datasets/utils.py", line 146, in read_image
    img = Image.open(path).convert('RGB')
  File "/home/yongxuan/.local/lib/python3.8/site-packages/PIL/Image.py", line 921, in convert
    self.load()
  File "/home/yongxuan/.local/lib/python3.8/site-packages/PIL/ImageFile.py", line 242, in load
    s = read(self.decodermaxblock)
  File "/home/yongxuan/.local/lib/python3.8/site-packages/PIL/PngImagePlugin.py", line 959, in load_read
    return self.fp.read(read_bytes)
KeyboardInterrupt